---
title: "ACOTSP 1000-4500: Estimation of parameter importance with Random Forests (Ranking)"
author: "Leslie Pérez Cáceres"
output:
  pdf_document: default
  html_notebook: default
  toc: TRUE
---

```{r include=FALSE}
library(irace)
library(randomForest)
library(randomForestExplainer)
library(knitr)
library(kableExtra)
```

In this document we are testing how to use Random Forest to assess importance and 
interactions of parameters based on the data gathered by irace.

For the analysis below we use as example ACOTSP:

- 20 secs cut off time (long)
- 11 parameters
- 400 instances sizes (1000,1500,2000,2500,3000,3500,4000,4500)
- 3000 experiments configuration budget / 5000 experiments configuration budget

We use random forest for predicting 

1. configuration normalized ranking
1. configuration imputed ranking
2. configuration imputed ranking quartile

Models are trained using default settings of the package Random Forest, excepting
the number of trees that was set to 300. We have access to the following measures 
that can be considered indicators of importance:

- mean_min_depth: mean depth of the subtree closest to the tree root, where a variable 
is root of the sub tree. 
- no_of_nodes: number of nodes in which the variable was used to split
- mse_increase: increment of prediction mean squared error
- no_of_trees: number of trees in which the variable was used
- times_a_root: number of times a variable was selected as root variable
- accuracy_decrease: measure of the classification accuracy (only for classification models)

For this analysis we use data generated by irace, it is possible to select 
a subset of the data and perform the analysis. The data is imputed and there is
a procedure to analyze importance based on a reference variable and a retraining 
scheme to assess real importance in conditional parameters. The instance is also used
as a predictor in this data. (details in another document)

There are some things that should be investigated regarding the best way to use the
models to asses interaction and importance:

1. Discretising numerical variables for prediction: based on a comment I got
that RF are biased to select numerical variables as split. This will be particularly
interesting and in line with the fact that irace defines a sampling range around
the current value.

2. Adjusting the number of trees and depth of them. My intuition is that smaller more
smaller trees would be more useful in the task of detecting importance. This is because
lower level splits are not as interesting and higher level splits. Also, to be used as a 
post-execution analysis tool the execution time required to build the model depends
on these parameters.

3. How to understand how this importance or interaction is materialized i.e., 
which are the best parameter values ans how these interact. Can we have an heuristic
idea of this interpreting the forest splits?

4. How to interpret instance importance and interaction when using models not predicting 
directly the performance. Can this help detecting heterogeneous sets?

In the following examples we use the *ranking as the dependent variable* when training,
thus the trained random forest predicts the mean ranking of a configuration. 
In these experiments the variable instance should not be a good as predictor 
compared to a model trained to predict performance directly. Despite this,
interactions of the instance variable with other variables are possible
and might indicate heterogeneity of the benchmark. In this model all irace data execution
was used for training. Note that due to the focused nature of irace data (given model 
convergence) there might be contradicting or not consistent interactions in the data.


# 1. Configuration normalized ranking as dependent variable

The data set used to train this model defines the variable to predict as the normalized
ranking. Ranking is normalized as:

```
(rank - 1) / (n_instances - 1)
```

where `rank` is the rank of a of a configuration in an instance and `n_instances` is the
number of instances used during the execution of irace.

We show importance measures ordered by the mean min depth given that the interaction
analysis is based on this measure.

```{r}
load("../model_data/model-acotsp1000-4500-ranking.Rdata")
importance_frame = model$importance_frame
important_parameters = model$important_parameters
full_interactions_frame = model$full_interactions_frame
interactions_frame = model$interactions_frame
kable(importance_frame[order(importance_frame[,"mean_min_depth"]),])  %>%  
      kable_styling(latex_options="scale_down")
```

We can plot two importance measures using the randomForestExplainer package, we choose the to show the 
mean min depth in the x axis and the mse increase in the y axis. Top 7 variables are highlighted.
In this case, since we are not predicting performance the effect of instance variable in model performance must
be interpreted carefully. These plots are interesting given that contrast importance for ranking prediction in 
terms of accuracy (mse_increase) and in terms of early importance the tree more in line with classification
goals (mean min depth).

```{r fig1, out.width = '75%', fig.align = "center"}

suppressWarnings(plot_multi_way_importance(importance_frame, size_measure = "p_value", 
                          y_measure="mse_increase", x_measure="mean_min_depth", 
                          no_of_labels=7))

```

We can also visualize the relationship between importance measures, this could help to
understand which indicator is more suited or can be used as a complement of other:

```{r fig2, out.width = '70%',  fig.align = "center", message=FALSE}
plot_importance_rankings(importance_frame, measures=c("mse_increase", "mean_min_depth", 
                                                      "no_of_nodes", "times_a_root"))
```


We perform an analysis of conditional parameters importance using a filtering and re training strategy 
and apply an irrelevant parameter filter by including a reference parameter. After this process
the most important 5 parameters are detected.

Important parameters:
```{r}
print(important_parameters)
```

Next, we run the interaction analysis only over important parameters.
This is assuming the interactions one cares to detect are related to them, which
might be not entirely correct ans should be evaluated as heuristic.
The importance of interactions is calculated based on the mean min depth indicator
in its conditional version.

Parameter interaction importance:
```{r}
kable(full_interactions_frame)  %>%  kable_styling(latex_options="scale_down")
```

For this example we aggregate bidirectional (`param1:param2` and `param2:param2`) interactions, 
this is done given that we assume that the hierarchy of the interaction is not well represented
in the forest and this should be analyzed separately. We also filter interactions using the reference
parameter to remove all not relevant interactions. Once this process is done, the importance 
of most relevant interactions is summarized.

Relevant parameter interactions:
```{r}
kable(interactions_frame) %>% kable_styling(latex_options="scale_down")
```


# 2. Configuration imputed ranking as dependent variable

For training the model we must impute the dependent variable (ranking) since some 
configurations are not executed in some instances. We assume these configurations 
to be worst than the configurations executed in the instance, after imputation 
all configurations have a ranking assigned for each instance. 

The parameter importance measures: 

```{r}
load("../model_data/model-acotsp1000-4500-iranking.Rdata")
importance_frame = model$importance_frame
important_parameters = model$important_parameters
full_interactions_frame = model$full_interactions_frame
interactions_frame = model$interactions_frame
kable(importance_frame[order(importance_frame[,"mean_min_depth"]),])  %>%  
      kable_styling(latex_options="scale_down")
```


We plot importance as above to visualize how the mse increase and mean min depth are 
related:

```{r fig3, out.width = '75%', fig.align = "center"}

suppressWarnings(plot_multi_way_importance(importance_frame, size_measure = "p_value", 
                          y_measure="mse_increase", x_measure="mean_min_depth", 
                          no_of_labels=7))

```

We visualize the relationship between importance measures, this could help to
understand which indicator is more suited or can be used as a complement of other.

```{r fig4, out.width = '70%', fig.align = "center", message=FALSE}
plot_importance_rankings(importance_frame, measures=c("mse_increase", "mean_min_depth", 
                                                      "no_of_nodes", "times_a_root"))
```

Important parameters:
```{r}
print(important_parameters)
```

Parameter interaction importance:
```{r}
kable(full_interactions_frame)  %>%  kable_styling(latex_options="scale_down")
```

For this example we aggregate bidirectional (`param1:param2` and `param2:param2`) interactions, 
this is done given that we assume that the hierarchy of the interaction is not well represented
in the forest and this should be analyzed separately. We also filter interactions using the reference
parameter to remove all not relevant interactions. Once this process is done, the importance 
of most relevant interactions is summarized.

Relevant parameter interactions:
```{r}
kable(interactions_frame) %>% kable_styling(latex_options="scale_down")
```

# 3.Configuration imputed ranking quantile as dependent variable

In this example we use the imputed ranking quartile as the dependent variable when training,
thus the trained random forest predicts the mean ranking quartile of a configuration.

In this example the ACOTSP data is used to predict solution quality similarly
of how it is used in SMAC and GGA++. The intuition is that in these models
instance is probably the best predictor of the quality due to the different sizes that
compose the instance set and the nature of the configuration objective (tour length).


Parameter importance:
```{r }
load("../model_data/model-acotsp1000-4500-qranking.Rdata")
importance_frame = model$importance_frame
full_interactions_frame = model$full_interactions_frame
interactions_frame = model$interactions_frame
important_parameters = model$important_parameters
kable(importance_frame[order(importance_frame[,"mean_min_depth"]),]) %>%
      kable_styling(latex_options="scale_down")
```

As expected the instance is the most important variable, the other parameters do not 
have the same ranking in the different benchmarks. 

We plot the importance measures  min mean depth and 
the mse increase to observe better this difference. The instance is removed in the 
plot so its possible to see more clearly other parameters. 


```{r fig5,  out.width = '70%', fig.align = "center"}

plot_multi_way_importance(importance_frame[importance_frame[,"variable"]!="instance",], size_measure = "p_value",
                          y_measure="mse_increase", x_measure="mean_min_depth", no_of_labels=7)

```

We visualize the relationship between importance measures, this could help to
understand which indicator is more suited or can be used as a complement of other.

```{r fig6, out.width = '70%', fig.align = "center", message=FALSE}
plot_importance_rankings(importance_frame, measures=c("mse_increase", "mean_min_depth", 
                                                      "no_of_nodes", "times_a_root"))
```

Filtered important parameters:
```{r}
print(important_parameters)

```

We use the mean_min_depth measure as reference given that this measure can
be extended to assess interactions and run the interaction analysis to find the importance
of interactions between the selected important parameters.
This is done by extending the definition of mean_min_depth to be calculated in max subtrees in which one
variable is root.

```{r}
kable(full_interactions_frame)  %>%  kable_styling(latex_options="scale_down")
```

We aggregate interactions with their inverse given that for now we are not interested
in the direction of the interaction. Once we aggregate to have bidirectional interactions
and filter dummy interactions, we get a matrix where the relevant importance of
interactions are summarized:

```{r}
kable(interactions_frame)  %>%  kable_styling(latex_options="scale_down")
```

